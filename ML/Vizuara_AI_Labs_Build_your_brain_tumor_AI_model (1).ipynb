{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNU1XQDKiJz7"
      },
      "source": [
        "**<center><font size=5>Vizuara AI Labs: Build your brain tumor AI model</font></center>**\n",
        "***\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "- <a href='#intro'>1. Project Overview and Objectives</a>\n",
        "    - <a href='#dataset'>1.1. Data Set Description</a>\n",
        "    - <a href='#tumor'>1.2. What is Brain Tumor?</a>\n",
        "- <a href='#env'>2. Setting up the Environment</a>\n",
        "- <a href='#import'>3. Data Import and Preprocessing</a>\n",
        "- <a href='#cnn'>4. Building the AI model</a>\n",
        "- <a href='#cnn'>5. Model evaluation</a>\n",
        "- <a href='#concl'>6. Testing the model</a>\n",
        "- <a href='#concl'>7. Conclusion</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFmp8VgiS76"
      },
      "source": [
        "# Introduction\n",
        "Welcome to the Vizuara AI Labs project notebook. This guide is designed to help you build your own machine learning model for medical imaging diagnosis, starting with brain tumor detection. The structure of this notebook is organized into modular building blocks, allowing you to easily adapt and apply this workflow to other projects, such as heart disease classification, by modifying specific sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKyw9ku8ifnr"
      },
      "source": [
        "# <a id='intro'>1. Project Overview and Objectives</a>\n",
        "\n",
        "The main purpose of this project was to build a CNN model that would classify if subject has a tumor or not base on MRI scan.\n",
        "\n",
        "## <a id='dataset'>1.1. Data Set Description</a>\n",
        "\n",
        "The image data that was used for this problem is [Brain MRI Images for Brain Tumor Detection](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection). It conists of MRI scans of two classes:\n",
        "\n",
        "* `NO` - no tumor, encoded as `0`\n",
        "* `YES` - tumor, encoded as `1`\n",
        "\n",
        "Unfortunately, the data set description doesn't hold any information where this MRI scans come from and so on.\n",
        "\n",
        "## <a id='tumor'>1.2. What is Brain Tumor?</a>\n",
        "\n",
        "> A brain tumor occurs when abnormal cells form within the brain. There are two main types of tumors: cancerous (malignant) tumors and benign tumors. Cancerous tumors can be divided into primary tumors, which start within the brain, and secondary tumors, which have spread from elsewhere, known as brain metastasis tumors. All types of brain tumors may produce symptoms that vary depending on the part of the brain involved. These symptoms may include headaches, seizures, problems with vision, vomiting and mental changes. The headache is classically worse in the morning and goes away with vomiting. Other symptoms may include difficulty walking, speaking or with sensations. As the disease progresses, unconsciousness may occur.\n",
        ">\n",
        "> ![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Hirnmetastase_MRT-T1_KM.jpg)\n",
        ">\n",
        "> *Brain metastasis in the right cerebral hemisphere from lung cancer, shown on magnetic resonance imaging.*\n",
        "\n",
        "Source: [Wikipedia](https://en.wikipedia.org/wiki/Brain_tumor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzb8Tvybf2mD"
      },
      "source": [
        "\n",
        "# <a id='intro'>2. Setting up the Environment: Import Statements</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "MEtuVaY6f2mF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EklzUuiXf2mG"
      },
      "source": [
        "# <a id='intro'>3(a) Data Import</a>\n",
        "\n",
        "When working on different projects, you will need to load a different dataset. The best way to load a dataset is as follows:\n",
        "\n",
        "(a) Upload the dataset to Google Drive\n",
        "\n",
        "(b) The image path will be `/content/drive/My Drive/name_of_your_dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFj7sqS-gAw1",
        "outputId": "33616936-6a79-4d7f-c8d0-17687e9ba5aa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkHp8jy5Yn4-"
      },
      "source": [
        "# <a id='intro'>3(b) Data Processing</a>\n",
        "\n",
        "1. First, we create a data list for storing image data in numpy array form\n",
        "2. Secondly, we create a paths list for storing paths of all images\n",
        "3. Thirdly, we create result list for storing one hot encoded form of target class whether normal or tumor\n",
        "\n",
        "The label 0 is transformed into [1, 0] (one-hot encoding).\n",
        "\n",
        "The label 1 is transformed into [0, 1] (one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "O0wV4lRmf2mG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell updates result list for images with tumor\n",
        "\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/drive/My Drive/brain_tumor_dataset/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3gHbYkMyf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell updates result list for images without tumor\n",
        "\n",
        "paths = []\n",
        "for r, d, f in os.walk(r\"/content/drive/My Drive/brain_tumor_dataset/no\"):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOjTinkQf2mH",
        "outputId": "d315af2b-cbec-49cb-8d32-a411767c80a3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2us8AzNbks5T",
        "outputId": "0c4b7d64-1e67-404c-a270-bd1d15c6e5d5"
      },
      "outputs": [],
      "source": [
        "print(f'Total number of images we have: {len(data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8o03PVTpf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "result = np.array(result)\n",
        "result = result.reshape(139,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seqqfDZUf2mH"
      },
      "source": [
        "## <a id='intro'>3.1. Splitting the data into training and testing</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KQKoUzzXf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVf6j9BkkY2O",
        "outputId": "5c829d93-f4b2-480b-c69e-9692c5c7795e"
      },
      "outputs": [],
      "source": [
        "print(f'Number of images in training data: {len(x_train)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed3qC8LzkmnB",
        "outputId": "7b75e86f-bbc9-4f14-b556-6f7a30634bfa"
      },
      "outputs": [],
      "source": [
        "print(f'Number of images in testing data: {len(x_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB4R2DrOf2mH"
      },
      "source": [
        "# <a id='intro'>4. Building the AI model</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQm07qElf2mH"
      },
      "source": [
        "## <a id='dataset'>4.1. Model Description</a>\n",
        "\n",
        "In this step, we are constructing an AI model that uses a Convolutional Neural Network (CNN), which is particularly good for image recognition tasks. Our model begins with two convolutional layers that have 32 filters each; these layers are designed to detect basic patterns in the brain MRI images, like edges and textures.\n",
        "\n",
        "## <a id='dataset'>4.2 Batch normalization</a>\n",
        "\n",
        "\n",
        "We apply batch normalization after the convolutional layers to accelerate training by scaling the outputs to a standard range.\n",
        "\n",
        "## <a id='dataset'>4.3 Pooling</a>\n",
        "\n",
        "Next, we introduce a pooling layer to reduce the dimensionality of the data, which helps the model to focus on the important features, and a dropout layer to prevent overfitting, which is when the model learns the training data too well and performs poorly on new data. We repeat this pattern of convolutional, batch normalization, pooling, and dropout layers with 64 filters in the convolutional layers to capture more complex patterns.\n",
        "\n",
        "## <a id='dataset'>4.4 Fully connected layer</a>\n",
        "\n",
        "After processing through these layers, the data is flattened into a one-dimensional array so it can be fed into densely connected layers, which will make the final decisions about what the patterns represent – in our case, whether there is a tumor or not.\n",
        "\n",
        "## <a id='dataset'>4.5 Activation function and optimizer</a>\n",
        "\n",
        "\n",
        "The last dense layer uses softmax activation to output probabilities for each class, which completes our model architecture. We compile the model with a categorical crossentropy loss function, which is suitable for multi-class classification problems, and choose the Adamax optimizer, an adaptation of the Adam optimizer that is designed to work well with models that have embeddings and sparse data.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png\" alt=\"CNN Architecture\" width=\"700\"/>\n",
        "\n",
        ">\n",
        "> *Schematic diagram of a Convolutional Neural Network (CNN): starting with an input image, the network applies multiple convolutional layers to detect features, interspersed with subsampling (pooling) layers to reduce dimensionality, and culminates in fully connected layers that lead to the final output classification*\n",
        "\n",
        "Source: [Wikipedia](https://en.wikipedia.org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC50dhJBf2mI",
        "outputId": "29558532-5772-44cc-a380-3fcb76156bc4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\n",
        "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
        "\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
        "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY3zoEWOf2mI",
        "outputId": "1310b3b9-514e-4af9-9813-fdeee6869a73",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03LnNGYPoc9r"
      },
      "source": [
        "# <a id='intro'>5. Model evaluation</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EItLKokoyWU"
      },
      "source": [
        "## <a id='intro'>5.1 What does the training process mean?</a>\n",
        "\n",
        "This section is the training process of a machine learning model using a Convolutional Neural Network (CNN) architecture in Google Colab. The training is set to run for 30 epochs, which means the model will have 30 complete passes through the entire training dataset. During each epoch, the model learns by adjusting its weights to minimize the difference between its predictions and the actual data.\n",
        "\n",
        "The batch size is set to 40, indicating that the model will use 40 images at a time to update its weights. The 'verbose' parameter set to 1 enables progress logs to be displayed, showing us the loss (a measure of how far the model's predictions are from the actual labels) and validation loss (the same measure, but calculated using a separate set of data not used in training) after each epoch.\n",
        "\n",
        "From the output, we can see that as the epochs progress, both the training loss and the validation loss generally decrease, which suggests that the model is learning and improving its predictions on both the training and validation datasets. This output is crucial for monitoring the training process and determining if and when the model is ready for evaluation or deployment.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZtg7nRf2mI",
        "outputId": "ef7e1ebc-43f3-49c7-a63d-2cb69ebc2dfe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmcNa48Bf2mI"
      },
      "source": [
        "## <a id='intro'>5.2 Plotting losses</a>\n",
        "\n",
        "The plot shows the model's loss on the test set and the validation set over the course of training epochs. The 'loss' refers to the value that a machine learning model tries to minimize during training. In this context, 'test loss' typically would refer to the loss calculated on a separate test set that is not used during the training process, whereas 'validation loss' refers to the loss calculated on a validation set, which is used to monitor and tune the model's performance during training.\n",
        "\n",
        "In the plot shown, after an initial sharp decline, both losses decrease and tend to converge as the epochs increase, which suggests that the model is learning and generalizing well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vh0qKfaNf2mI",
        "outputId": "d709ab85-fb01-4082-bd63-5203a6bee2fc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Test', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXsbRnsjf2mI"
      },
      "source": [
        "# <a id='intro'>6. Testing the model</a>\n",
        "\n",
        "In the testing phase of our machine learning project, we evaluate the model's performance using new images it hasn't seen before. The code snippet demonstrates how to test the model with an MRI image that has a tumor and one which does not have a tumor.\n",
        "\n",
        "The process involves loading the image, resizing it to match the input size the model expects, and then reshaping it to the appropriate format for the model to process. The model then predicts whether a tumor is present or not.\n",
        "\n",
        "The result, displayed below the image, shows the model's confidence level in its prediction. In both cases, we see that the model correctly classifies a \"non-tumor\" image as \"not a tumor\" and a \"tumor\" image as a \"tumor\" image.\n",
        "\n",
        "This means that our model is trained successfully now!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "8Nq86edDf2mI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def names(number):\n",
        "    if number==0:\n",
        "        return 'Its a Tumor'\n",
        "    else:\n",
        "        return 'No, Its not a tumor'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "rMmxMCzGf2mI",
        "outputId": "000043b2-0a95-4b61-89ad-74066b9c2ce9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "img = Image.open(r\"/content/drive/My Drive/brain_tumor_dataset/no/N11.jpg\")\n",
        "x = np.array(img.resize((128,128)))\n",
        "x = x.reshape(1,128,128,3)\n",
        "res = model.predict_on_batch(x)\n",
        "classification = np.where(res == np.amax(res))[1][0]\n",
        "imshow(img)\n",
        "print(str(res[0][classification]*100) + '% Confidence This Is ' + names(classification))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "OLOZtPmKV6ty",
        "outputId": "dda69b87-24da-4838-c46e-22f65bc5cb0e"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "img = Image.open(r\"/content/drive/My Drive/brain_tumor_dataset/yes/Y3.jpg\")\n",
        "x = np.array(img.resize((128,128)))\n",
        "x = x.reshape(1,128,128,3)\n",
        "res = model.predict_on_batch(x)\n",
        "classification = np.where(res == np.amax(res))[1][0]\n",
        "imshow(img)\n",
        "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "cellView": "form",
        "id": "PF8rhZhDO3dy"
      },
      "outputs": [],
      "source": [
        "#@title Provide a title for your app:\n",
        "heading_title = \"Raj brain tumor classification app\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "cellView": "form",
        "id": "UKtsxpKMO4d2"
      },
      "outputs": [],
      "source": [
        "#@title You can add some example images that you want to be present in your app by default. The user can see use these images to quickly and easily test the model. How many example images do you want to load?\n",
        "num_examples = 2 # @param {type:\"slider\", min:1, max:6, step:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "mIwMO7QsO68R",
        "outputId": "09fe2afc-c5df-478a-9c45-48b165c2b576"
      },
      "outputs": [],
      "source": [
        "#@title Enter the paths for the example images that you want displayed in your app by default. The user can use these images to quickly and easily test the model. Note: You can get the path for the file from the left sidebar. Simply run the code below, select the image file you want to include from its folder, right-click and select 'Copy path'. Then paste the path in the input box displayed:\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "examples=[]\n",
        "for i in range(num_examples):\n",
        "  example_path = input(f\"example_path_{i+1}:  \")\n",
        "  examples.append(example_path)\n",
        "\n",
        "#Displaying the selected images side by side\n",
        "rows = 1\n",
        "plt.figure(figsize=(16, 8))\n",
        "for num, x in enumerate(examples):\n",
        "    img = Image.open(x)\n",
        "    plt.subplot(rows,6,num+1)\n",
        "   # plt.title(x.split('.')[0])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "cellView": "form",
        "id": "OsuLl0tCPHUJ"
      },
      "outputs": [],
      "source": [
        "#@title You can also add some description and explanation to your app's interace if you want. Go ahead and specify some text for the description and the long description (if you want to):\n",
        "desc = \"Brain tumor app. Let's learn!\" # @param {type:\"string\"}\n",
        "long_desc = \"Select an image or upload one to predict if brain tumor is present or not\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "cellView": "form",
        "id": "CDfDohKzS7vs"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "#@title Select a Theme for Gradio Interface:\n",
        "theme_selection = \"Glass\" # @param [\"Base\", \"Default\", \"Glass\", \"Monochrome\", \"Soft\"]\n",
        "\n",
        "theme_dict = {\n",
        "    \"Base\": gr.themes.Base(),\n",
        "    \"Default\": gr.themes.Default(),\n",
        "    \"Glass\": gr.themes.Glass(),\n",
        "    \"Monochrome\": gr.themes.Monochrome(),\n",
        "    \"Soft\": gr.themes.Soft()\n",
        "}\n",
        "\n",
        "# The selected theme is determined by the user's dropdown selection\n",
        "selected_theme = theme_dict[theme_selection]\n",
        "\n",
        "# Now you can use the selected_theme variable when you create your Gradio interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "sDF__uyjTn8L"
      },
      "outputs": [],
      "source": [
        "def recognize_image(image):\n",
        "    # Resize the image to the expected dimensions\n",
        "    img = Image.fromarray(image).resize((128, 128))\n",
        "    # Convert the image to a NumPy array\n",
        "    x = np.array(img)\n",
        "    # Reshape the image to match the model input\n",
        "    x = x.reshape(1, 128, 128, 3)\n",
        "\n",
        "    # Make a prediction\n",
        "    res = model.predict_on_batch(x)\n",
        "    classification = np.where(res == np.amax(res))[1][0]\n",
        "\n",
        "    # Map the class index to the actual class name (assuming you have a list of class names)\n",
        "    class_names = ['No Tumor', 'Tumor']  # Example class names, update according to your model\n",
        "    result = f\"{names(classification)}\"\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "rKWEXBbuPMmO",
        "outputId": "37766c3b-90cd-45c2-b695-9280a9d2f8c9"
      },
      "outputs": [],
      "source": [
        "# Assuming recognize_image, examples, heading_title, desc, long_desc, and selected_theme are defined elsewhere.\n",
        "\n",
        "# Update the import for components\n",
        "image = gr.Image()\n",
        "label = gr.Label()\n",
        "\n",
        "# Create the interface with the updated component imports\n",
        "iface = gr.Interface(\n",
        "    fn=recognize_image,\n",
        "    inputs=image,\n",
        "    outputs=label,\n",
        "    examples=examples,\n",
        "    title=heading_title,\n",
        "    description=desc,\n",
        "    article=long_desc,\n",
        "    theme=selected_theme  # Make sure this is defined based on user selection as explained in previous messages\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8QKscILrZDp"
      },
      "source": [
        "# <a id='intro'>7. Conclusions</a>\n",
        "\n",
        "This notebook has guided you through creating a brain tumor classification model using a Convolutional Neural Network (CNN). We've covered essential steps such as preparing and loading data, designing and training the neural network, and finally testing its ability to classify MRI images accurately.\n",
        "\n",
        "**The skills and methods you've learned here aren't limited to just identifying brain tumors—they form the foundation for a wide range of image classification projects. You can apply the same techniques to different types of medical imagery, such as detecting signs of heart disease in echocardiograms or identifying various conditions using X-ray images.**\n",
        "\n",
        "Remember, the principles of loading your dataset, preprocessing the images, building and training the model, and evaluating its performance are similar, no matter what kind of images you're working with. The \"building blocks\" we've used can be rearranged and adapted to suit any image classification task you're interested in exploring.\n",
        "\n",
        "So, take what you've learned and start applying it to new challenges—the possibilities for what you can achieve are as broad as your imagination. Whether it's medical imaging or another field entirely, the tools you've mastered here are a solid foundation for your journey in AI and machine learning. Keep learning, keep building, and have fun exploring the vast potential of these technologies!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2sbbXsVsyl0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKRkkfuBLXc8"
      },
      "source": [
        "### Streamlit or Gradio for deployment\n",
        "### Few lines of code --> vary color scheme"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 165566,
          "sourceId": 377107,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30042,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
